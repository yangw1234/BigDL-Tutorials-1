{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import heapq\n",
    "\n",
    "import tensorflow as tf\n",
    "from zoo import init_nncontext\n",
    "from zoo.pipeline.api.net import TFOptimizer, TFDataset, TFPredictor\n",
    "from bigdl.optim.optimizer import *\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from bigdl.dataset import mnist\n",
    "from bigdl.dataset.transformer import *\n",
    "\n",
    "sys.path.append(\"./slim\")  # add the slim library\n",
    "from nets import lenet\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Extracting', '/tmp/mnist/train-images-idx3-ubyte.gz')\n",
      "('Extracting', '/tmp/mnist/train-labels-idx1-ubyte.gz')\n",
      "('Extracting', '/tmp/mnist/t10k-images-idx3-ubyte.gz')\n",
      "('Extracting', '/tmp/mnist/t10k-labels-idx1-ubyte.gz')\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 1\n",
    "data_num = 60000\n",
    "sc = init_nncontext()\n",
    "\n",
    "\n",
    "# get data, pre-process and create TFDataset\n",
    "def get_data_rdd(dataset):\n",
    "    (images_data, labels_data) = mnist.read_data_sets(\"/tmp/mnist\", dataset)\n",
    "    image_rdd = sc.parallelize(images_data[:data_num])\n",
    "    labels_rdd = sc.parallelize(labels_data[:data_num])\n",
    "    rdd = image_rdd.zip(labels_rdd) \\\n",
    "        .map(lambda rec_tuple: [normalizer(rec_tuple[0], mnist.TRAIN_MEAN, mnist.TRAIN_STD),\n",
    "                                np.array(rec_tuple[1])])\n",
    "    return rdd\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "training_rdd = get_data_rdd(\"train\")\n",
    "testing_rdd = get_data_rdd(\"test\")\n",
    "dataset = TFDataset.from_rdd(training_rdd,\n",
    "                             names=[\"features\", \"labels\"],\n",
    "                             shapes=[[28, 28, 1], []],\n",
    "                             types=[tf.float32, tf.int32],\n",
    "                             batch_size=1024,\n",
    "                             val_rdd=testing_rdd\n",
    "                             )\n",
    "\n",
    "# construct the model from TFDataset\n",
    "images, labels = dataset.tensors\n",
    "\n",
    "with slim.arg_scope(lenet.lenet_arg_scope()):\n",
    "    logits, end_points = lenet.lenet(images, num_classes=10, is_training=True)\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createAdam\n",
      "creating: createTop1Accuracy\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "creating: createTFTrainingHelper\n",
      "creating: createIdentityCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createDistriOptimizer\n",
      "creating: createTFValidationMethod\n",
      "creating: createEveryEpoch\n",
      "creating: createTrainSummary\n",
      "creating: createValidationSummary\n",
      "creating: createMaxEpoch\n",
      "WARNING:tensorflow:Issue encountered when serializing features:0.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "TFDataset instance has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing labels:0.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "TFDataset instance has no attribute 'name'\n",
      "CPU times: user 2.4 s, sys: 192 ms, total: 2.59 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a optimizer\n",
    "optimizer = TFOptimizer(loss, Adam(1e-3),\n",
    "                        val_outputs=[logits],\n",
    "                        val_labels=[labels],\n",
    "                        val_method=Top1Accuracy())\n",
    "optimizer.set_train_summary(TrainSummary(\"/tmp/az_lenet\", \"lenet\"))\n",
    "optimizer.set_val_summary(ValidationSummary(\"/tmp/az_lenet\", \"lenet\"))\n",
    "# kick off training\n",
    "optimizer.optimize(end_trigger=MaxEpoch(max_epoch))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.save(optimizer.sess, \"/tmp/lenet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/lenet/\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "creating: createTFNet\n",
      "predict accuracy is [0.9591]\n"
     ]
    }
   ],
   "source": [
    "# construct the model from TFDataset\n",
    "tf.reset_default_graph()\n",
    "dataset = TFDataset.from_rdd(testing_rdd,\n",
    "                                 names=[\"features\", \"labels\"],\n",
    "                                 shapes=[[28, 28, 1], [1]],\n",
    "                                 types=[tf.float32, tf.int32],\n",
    "                                 batch_per_thread=20\n",
    "                                 )\n",
    "images, labels = dataset.tensors\n",
    "\n",
    "labels = tf.squeeze(labels)\n",
    "\n",
    "with slim.arg_scope(lenet.lenet_arg_scope()):\n",
    "    logits, end_points = lenet.lenet(images, num_classes=10, is_training=False)\n",
    "\n",
    "predictions = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "correct = tf.expand_dims(tf.to_int32(tf.equal(predictions, labels)), axis=1)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"/tmp/lenet/\")\n",
    "\n",
    "    predictor = TFPredictor(sess, [correct])\n",
    "\n",
    "    accuracy = predictor.predict().mean()\n",
    "\n",
    "    print(\"predict accuracy is %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
